# PredicciÃ³n de HipertensiÃ³n Arterial con Modelos Avanzados
Se aplicaron modelos de clasificaciÃ³n para predecir la presencia de hipertensiÃ³n arterial a partir de datos clÃ­nicos fÃ¡cilmente obtenibles. La metodologÃ­a replica parcialmente dos enfoques recientes: uno basado en boosting de Ã¡rboles (XGBoost) y otro en aprendizaje profundo para datos tabulares (TabNet).

## ğŸ“š Dataset
Se usÃ³ el Stroke Prediction Dataset, que incluye variables como:
- Edad
- GÃ©nero
- Nivel promedio de glucosa
- IMC
- Enfermedades cardÃ­acas
- Tipo de trabajo, residencia y tabaquismo  
- Resultado: hipertensiÃ³n (sÃ­/no)

Este dataset fue elegido por su similitud con los datos utilizados en los artÃ­culos originales.

## ğŸ§  Modelos aplicados
- âœ… TabNet (modelo de deep learning para datos tabulares)
- âœ… XGBoost (con ajuste bÃ¡sico de parÃ¡metros)

Ambos modelos fueron implementados en Google Colab usando librerÃ­as como `xgboost`, `pytorch-tabnet`, `imbalanced-learn`, `scikit-learn` y `pandas`.

## ğŸ“Š EvaluaciÃ³n
Se utilizaron las siguientes mÃ©tricas para evaluar los modelos:
- Accuracy
- Precision
- Recall
- F1-score
- Matriz de confusiÃ³n
- GrÃ¡fico de importancia de variables

---

## ğŸ“° ArtÃ­culos de referencia
- ğŸ“„ XGBoost:  
  Dubey et al. (2024). Explainable and Interpretable Model for the Early Detection of Brain Stroke Using Optimized Boosting Algorithms.  
  [DOI: 10.3390/diagnostics14222514](https://www.mdpi.com/2075-4418/14/22/2514)
- ğŸ“„ TabNet:  
  Arik & Pfister (2021). *When Do Neural Nets Outperform Boosted Trees on Tabular Data?*   
  [https://doi.org/10.48550/arXiv.2305.02997](https://arxiv.org/pdf/2305.02997)

---

## âš™ï¸ Algoritmo 1: XGBoost
- Modelo: XGBClassifier (100 Ã¡rboles, eval_metric="logloss")
- Dataset: Healthcare Stroke Prediction Dataset (Kaggle)
- Balanceo: muestreo hÃ­brido
  - Undersampling de la clase mayoritaria
  - Oversampling con SMOTE de la clase minoritaria
- Interpretabilidad: grÃ¡fico SHAP para explicar la importancia de cada variable

### ğŸ“Š Resultados obtenidos
- Accuracy: 83.5â€¯%
- Precision: 82â€¯% (clase 1)
- Recall: 85â€¯% (clase 1)
- F1-score: 83â€¯%

## âš™ï¸ Modelo 2: TabNet

- Modelo: `TabNetClassifier` (entrenado por hasta 200 Ã©pocas con early stopping)
- Dataset: Healthcare Stroke Prediction Dataset (Kaggle)
- Balanceo de clases: SMOTE
- NormalizaciÃ³n: `StandardScaler`
- Interpretabilidad: grÃ¡fico de **importancia de variables** basado en `feature_importances_` del modelo

### ğŸ“Š Resultados obtenidos
- Accuracy: 85.8â€¯%
- Precision: 85â€¯% (clase 1)
- Recall: 88â€¯% (clase 1)
- F1-score: 86â€¯%

---

ğŸ“Œ Nota final:
Este trabajo busca replicar enfoques actuales para la predicciÃ³n mÃ©dica usando datos tabulares accesibles. Mientras que XGBoost representa un enfoque clÃ¡sico basado en Ã¡rboles potenciados, TabNet se posiciona como una alternativa moderna basada en redes neuronales profundas. Ambos ofrecen buen rendimiento, pero TabNet demuestra ser competitivo incluso frente a algoritmos tradicionalmente dominantes en este tipo de datos.
