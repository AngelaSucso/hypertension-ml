# PredicciÃ³n de HipertensiÃ³n Arterial con Machine Learning
Se aplicaron modelos de clasificaciÃ³n ya implementados en librerÃ­as de aprendizaje automÃ¡tico para predecir la presencia de hipertensiÃ³n arterial a partir de datos clÃ­nicos fÃ¡cilmente obtenibles. Se replica parcialmente la metodologÃ­a de dos artÃ­culos cientÃ­ficos que utilizan Random Forest y XGBoost para este propÃ³sito.

## ğŸ“š Dataset
Se usÃ³ el Stroke Prediction Dataset, que incluye variables como:
- Edad
- GÃ©nero
- Nivel promedio de glucosa
- IMC
- Enfermedades cardÃ­acas
- Estado civil, etc
- Resultado: hipertensiÃ³n (sÃ­/no)

Este dataset fue elegido por su similitud con los datos utilizados en los artÃ­culos originales.

## ğŸ§  Modelos aplicados
- âœ… Random Forest (con balanceo usando SMOTE)
- âœ… XGBoost (con ajuste bÃ¡sico de parÃ¡metros)

Ambos modelos fueron implementados usando librerÃ­as estÃ¡ndar como `scikit-learn`, `xgboost`, `imbalanced-learn` y `pandas`, ejecutados en Google Colab.

## ğŸ“Š EvaluaciÃ³n
Se utilizaron las siguientes mÃ©tricas para evaluar los modelos:
- Accuracy
- Precision
- Recall
- F1-score
- Matriz de confusiÃ³n
- GrÃ¡fico de importancia de variables

## ğŸ“° ArtÃ­culos de referencia
- ğŸ“„ Random Forest:  
  Zhao et al. (2021). Predicting the Risk of Hypertension Based on Several Easy-to-Collect Risk Factors.  
  [DOI: 10.3389/fpubh.2021.619429](https://www.frontiersin.org/articles/10.3389/fpubh.2021.619429)

- ğŸ“„ XGBoost:  
  Dubey et al. (2024). Explainable and Interpretable Model for the Early Detection of Brain Stroke Using Optimized Boosting Algorithms.  
  [DOI: 10.3390/diagnostics14222514](https://www.mdpi.com/2075-4418/14/22/2514)


## âš™ï¸ Algoritmo 1: Random Forest
- Modelo: RandomForestClassifier (100 Ã¡rboles)
- Dataset: Healthcare Stroke Prediction Dataset (Kaggle)
- Balanceo: SMOTE (oversampling de la clase minoritaria)
- Interpretabilidad: importancia de variables segÃºn el modelo Random Forest

### ğŸ“Š Resultados obtenidos
- Accuracy: 89.2â€¯%
- Precision: 88â€¯% (clase 1)
- Recall: 91â€¯% (clase 1)
- F1-score: 89â€¯%

## âš™ï¸ Algoritmo 2: XGBoost
- Modelo: XGBClassifier (100 Ã¡rboles, eval_metric="logloss")
- Dataset: Healthcare Stroke Prediction Dataset (Kaggle)
- Balanceo: muestreo hÃ­brido
  - Undersampling de la clase mayoritaria
  - Oversampling con SMOTE de la clase minoritaria
- Interpretabilidad: grÃ¡fico SHAP para explicar la importancia de cada variable

### ğŸ“Š Resultados obtenidos
- Accuracy: 83.5â€¯%
- Precision: 82â€¯% (clase 1)
- Recall: 85â€¯% (clase 1)
- F1-score: 83â€¯%


---

ğŸ“Œ Nota final:
Se busca replicar parte del enfoque de los artÃ­culos acadÃ©micos recientes usando datos tabulares accesibles y modelos clÃ¡sicos como Random Forest y XGBoost. Aunque los datos no son exactamente los mismos que en los papers, se mantiene la idea principal: evaluar tÃ©cnicas efectivas y fÃ¡ciles de implementar para problemas de predicciÃ³n mÃ©dica. Los algoritmos basados en Ã¡rboles siguen siendo una muy buena opciÃ³n en este tipo de tareas, sobre todo cuando se necesita interpretabilidad, buen rendimiento y facilidad de uso.

