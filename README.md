# PredicciÃ³n de HipertensiÃ³n Arterial con Modelos Avanzados
Se aplicaron modelos de clasificaciÃ³n para predecir la presencia de hipertensiÃ³n arterial a partir de datos clÃ­nicos fÃ¡cilmente obtenibles. La metodologÃ­a replica parcialmente dos enfoques recientes: uno basado en boosting de Ã¡rboles (XGBoost) y otro en aprendizaje profundo para datos tabulares (TabNet).

## ğŸ“š Datasets
### ğŸ’‰ [Blood Pressure Dataset](https://www.kaggle.com/datasets/pavanbodanki/blood-press/data)  
Se usÃ³ el **Blood Pressure Dataset** correspondiente a XGBoost, que contiene variables relacionadas con:
- Blood_Pressure_Abnormality  
- Level_of_Hemoglobin  
- Genetic_Pedigree_Coefficient  
- Age  
- BMI  
- Sex
- Pregnancy  
- Smoking  
- Physical_activity 
- **Resultado:** presiÃ³n arterial (alta o normal)  
ğŸ”— [Disponible en Kaggle](https://www.kaggle.com/datasets/pavanbodanki/blood-press/data)

### ğŸ§  [Hypertension Risk Model Dataset](https://www.kaggle.com/datasets/khan1803115/hypertension-risk-model-main)  
Se usÃ³ el **Hypertension Risk Model Dataset** correspondiente a TabNet, que considera factores de riesgo como:
- Edad  
- GÃ©nero  
- Peso y altura  
- IMC  
- Consumo de sal  
- Nivel de estrÃ©s  
- Actividad fÃ­sica y herencia genÃ©tica  
- **Resultado:** riesgo de hipertensiÃ³n (sÃ­/no)  
ğŸ”— [Disponible en Kaggle](https://www.kaggle.com/datasets/khan1803115/hypertension-risk-model-main)

---

## ğŸ§  Modelos aplicados
- âœ… XGBoost (con ajuste bÃ¡sico de parÃ¡metros)
- âœ… TabNet (modelo de deep learning para datos tabulares)

Ambos modelos fueron implementados en Google Colab usando librerÃ­as como `xgboost`, `pytorch-tabnet`, `imbalanced-learn`, `scikit-learn` y `pandas`.

## ğŸ“Š EvaluaciÃ³n
Se utilizaron las siguientes mÃ©tricas para evaluar los modelos:
- Accuracy
- Precision
- Recall
- F1-score
- Matriz de confusiÃ³n
- GrÃ¡fico de importancia de variables

---

## EvaluaciÃ³n comparativa intercambiando datasets para los modelos

### âš™ï¸ Algoritmo 1: XGBoost
- Modelo: XGBClassifier (100 Ã¡rboles, eval_metric="error")
- Dataset: Hypertension Risk Model Main (Kaggle)
- Interpretabilidad: grÃ¡fico SHAP para explicar la importancia de cada variable

#### ğŸ“Š Resultados obtenidos
- Accuracy: **88.3â€¯%**
- Precision: **81â€¯%** (clase 1)
- Recall: **82â€¯%** (clase 1)
- F1-score: **81â€¯%** (clase 1)

### âš™ï¸ Modelo 2: TabNet

- Modelo: `TabNetClassifier` (entrenado por hasta 200 Ã©pocas con early stopping)
- Dataset: Blood Pressure Dataset (Kaggle)
- Interpretabilidad: grÃ¡fico de **importancia de variables** basado en `feature_importances_` del modelo

#### ğŸ“Š Resultados obtenidos
- Accuracy: **87.5â€¯%**
- Precision: **88â€¯%** (clase 1)
- Recall: **86â€¯%** (clase 1)
- F1-score: **87â€¯%** (clase 1)

---

ğŸ“Œ Nota final:
Este trabajo busca replicar enfoques actuales para la predicciÃ³n mÃ©dica usando datos tabulares accesibles. Mientras que XGBoost representa un enfoque clÃ¡sico basado en Ã¡rboles potenciados, TabNet se posiciona como una alternativa moderna basada en redes neuronales profundas. Ambos ofrecen buen rendimiento, pero TabNet demuestra ser competitivo incluso frente a algoritmos tradicionalmente dominantes en este tipo de datos.
